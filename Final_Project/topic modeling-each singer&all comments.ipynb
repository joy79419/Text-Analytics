{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zgh\\Anaconda2\\envs\\Python3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#import pyLDAvis.gensim as gensimvis\n",
    "#import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnny_Bliss\n",
      " \n",
      "(0, '0.042*\"song\" + 0.026*\"like\" + 0.017*\"really\" + 0.014*\"sing\" + 0.014*\"good\" + 0.013*\"voice\" + 0.011*\"sound\" + 0.011*\"cover\" + 0.010*\"artist\" + 0.010*\"go\" + 0.008*\"well\" + 0.008*\"adele\"')\n",
      "(1, '0.020*\"one\" + 0.011*\"like\" + 0.010*\"favorite\" + 0.010*\"alicia\" + 0.010*\"get\" + 0.010*\"song\" + 0.010*\"true\" + 0.007*\"playoff\" + 0.007*\"move\" + 0.007*\"see\" + 0.007*\"johnny\" + 0.007*\"simply\"')\n",
      "(2, '0.033*\"like\" + 0.020*\"performance\" + 0.018*\"team\" + 0.018*\"great\" + 0.016*\"good\" + 0.016*\"well\" + 0.012*\"think\" + 0.012*\"go\" + 0.012*\"get\" + 0.010*\"song\" + 0.008*\"him\" + 0.008*\"3\"')\n",
      "(3, '0.027*\"like\" + 0.016*\"voice\" + 0.016*\"really\" + 0.013*\"song\" + 0.013*\"go\" + 0.011*\"good\" + 0.011*\"sing\" + 0.011*\"johnny\" + 0.011*\"feel\" + 0.008*\"top\" + 0.008*\"sorry\" + 0.008*\"hear\"')\n",
      " \n",
      "Christiana_Danielle\n",
      " \n",
      "(0, '0.017*\"voice\" + 0.017*\"like\" + 0.014*\"im\" + 0.011*\"win\" + 0.010*\"song\" + 0.010*\"really\" + 0.009*\"good\" + 0.008*\"go\" + 0.008*\"christiana\" + 0.008*\"well\" + 0.007*\"best\" + 0.007*\"omg\"')\n",
      "(1, '0.023*\"christiana\" + 0.020*\"alicia\" + 0.016*\"go\" + 0.015*\"jackie\" + 0.014*\"like\" + 0.014*\"terrence\" + 0.010*\"get\" + 0.009*\"know\" + 0.009*\"would\" + 0.009*\"team\" + 0.008*\"best\" + 0.008*\"performance\"')\n",
      "(2, '0.039*\"like\" + 0.014*\"good\" + 0.011*\"performance\" + 0.010*\"her\" + 0.010*\"make\" + 0.009*\"voice\" + 0.008*\"vote\" + 0.008*\"alicia\" + 0.008*\"girl\" + 0.007*\"song\" + 0.007*\"please\" + 0.007*\"christiana\"')\n",
      "(3, '0.032*\"song\" + 0.015*\"like\" + 0.014*\"performance\" + 0.013*\"voice\" + 0.012*\"well\" + 0.011*\"get\" + 0.009*\"it\" + 0.008*\"make\" + 0.008*\"one\" + 0.008*\"christiana\" + 0.007*\"her\" + 0.007*\"good\"')\n",
      " \n",
      "Kelsea_Johnson\n",
      " \n",
      "(0, '0.017*\"like\" + 0.016*\"song\" + 0.015*\"best\" + 0.015*\"voice\" + 0.013*\"sing\" + 0.013*\"would\" + 0.013*\"show\" + 0.012*\"alicia\" + 0.012*\"go\" + 0.012*\"sound\" + 0.011*\"team\" + 0.011*\"girl\"')\n",
      "(1, '0.082*\"kelsea\" + 0.044*\"like\" + 0.013*\"good\" + 0.012*\"make\" + 0.012*\"voice\" + 0.012*\"song\" + 0.012*\"one\" + 0.012*\"go\" + 0.010*\"alicia\" + 0.009*\"much\" + 0.009*\"team\" + 0.009*\"performance\"')\n",
      "(2, '0.026*\"lauryn\" + 0.026*\"hill\" + 0.022*\"voice\" + 0.012*\"hope\" + 0.011*\"like\" + 0.010*\"great\" + 0.010*\"song\" + 0.009*\"really\" + 0.009*\"much\" + 0.009*\"top\" + 0.008*\"think\" + 0.008*\"vibe\"')\n",
      "(3, '0.026*\"make\" + 0.018*\"like\" + 0.015*\"voice\" + 0.013*\"christiana\" + 0.012*\"top\" + 0.011*\"think\" + 0.010*\"alicia\" + 0.010*\"song\" + 0.010*\"jackie\" + 0.009*\"it\" + 0.009*\"12\" + 0.008*\"artist\"')\n",
      " \n",
      "Terrence_Cunningham\n",
      " \n",
      "(0, '0.028*\"like\" + 0.013*\"piano\" + 0.010*\"say\" + 0.010*\"make\" + 0.010*\"terrence\" + 0.009*\"well\" + 0.008*\"time\" + 0.008*\"dislike\" + 0.008*\"one\" + 0.008*\"song\" + 0.007*\"people\" + 0.007*\"boring\"')\n",
      "(1, '0.022*\"get\" + 0.014*\"he\" + 0.012*\"like\" + 0.012*\"voice\" + 0.009*\"something\" + 0.009*\"performance\" + 0.008*\"artist\" + 0.008*\"overrate\" + 0.008*\"song\" + 0.008*\"want\" + 0.007*\"piano\" + 0.007*\"terrence\"')\n",
      "(2, '0.024*\"like\" + 0.012*\"alicia\" + 0.012*\"christiana\" + 0.012*\"get\" + 0.012*\"show\" + 0.011*\"im\" + 0.011*\"he\" + 0.010*\"feel\" + 0.009*\"song\" + 0.009*\"voice\" + 0.008*\"well\" + 0.008*\"know\"')\n",
      "(3, '0.014*\"piano\" + 0.012*\"performance\" + 0.010*\"voice\" + 0.009*\"one\" + 0.008*\"terrence\" + 0.008*\"go\" + 0.007*\"great\" + 0.007*\"get\" + 0.007*\"show\" + 0.006*\"like\" + 0.006*\"he\" + 0.006*\"im\"')\n",
      " \n",
      "Drew_Cole\n",
      " \n",
      "(0, '0.022*\"drew\" + 0.019*\"song\" + 0.017*\"voice\" + 0.015*\"like\" + 0.012*\"vote\" + 0.012*\"go\" + 0.012*\"win\" + 0.010*\"best\" + 0.008*\"season\" + 0.008*\"wilkes\" + 0.008*\"listen\" + 0.008*\"twitter\"')\n",
      "(1, '0.027*\"adam\" + 0.018*\"well\" + 0.017*\"country\" + 0.016*\"go\" + 0.016*\"draw\" + 0.015*\"make\" + 0.013*\"voice\" + 0.013*\"like\" + 0.012*\"really\" + 0.012*\"season\" + 0.010*\"jackie\" + 0.009*\"wrong\"')\n",
      "(2, '0.016*\"adam\" + 0.015*\"country\" + 0.015*\"song\" + 0.015*\"go\" + 0.014*\"really\" + 0.013*\"team\" + 0.010*\"one\" + 0.010*\"jackie\" + 0.009*\"he\" + 0.009*\"performance\" + 0.009*\"sarah\" + 0.009*\"favorite\"')\n",
      "(3, '0.017*\"favorite\" + 0.015*\"jackie\" + 0.013*\"draw\" + 0.013*\"show\" + 0.011*\"two\" + 0.011*\"go\" + 0.009*\"country\" + 0.009*\"it\" + 0.009*\"know\" + 0.009*\"say\" + 0.009*\"think\" + 0.009*\"else\"')\n",
      " \n",
      "Jackie_Verna\n",
      " \n",
      "(0, '0.027*\"like\" + 0.018*\"adam\" + 0.017*\"jackie\" + 0.013*\"song\" + 0.011*\"choice\" + 0.011*\"performance\" + 0.010*\"make\" + 0.010*\"last\" + 0.010*\"win\" + 0.009*\"country\" + 0.009*\"think\" + 0.009*\"say\"')\n",
      "(1, '0.028*\"jackie\" + 0.014*\"get\" + 0.014*\"like\" + 0.014*\"make\" + 0.013*\"good\" + 0.013*\"adam\" + 0.012*\"think\" + 0.011*\"mia\" + 0.011*\"singer\" + 0.010*\"choice\" + 0.009*\"top\" + 0.009*\"country\"')\n",
      "(2, '0.022*\"adam\" + 0.021*\"mia\" + 0.019*\"reid\" + 0.016*\"im\" + 0.014*\"jackie\" + 0.013*\"go\" + 0.011*\"voice\" + 0.009*\"well\" + 0.009*\"would\" + 0.009*\"drew\" + 0.008*\"think\" + 0.008*\"move\"')\n",
      "(3, '0.023*\"jackie\" + 0.014*\"like\" + 0.014*\"reid\" + 0.012*\"song\" + 0.012*\"one\" + 0.010*\"country\" + 0.010*\"performance\" + 0.010*\"go\" + 0.009*\"think\" + 0.009*\"season\" + 0.008*\"adam\" + 0.008*\"best\"')\n",
      " \n",
      "Mia_Boostrom\n",
      " \n",
      "(0, '0.024*\"song\" + 0.024*\"like\" + 0.021*\"mia\" + 0.017*\"great\" + 0.012*\"bad\" + 0.011*\"performance\" + 0.010*\"one\" + 0.009*\"night\" + 0.008*\"jackie\" + 0.008*\"good\" + 0.008*\"singer\" + 0.008*\"choose\"')\n",
      "(1, '0.019*\"performance\" + 0.014*\"bad\" + 0.013*\"one\" + 0.012*\"like\" + 0.009*\"note\" + 0.009*\"use\" + 0.009*\"go\" + 0.007*\"really\" + 0.007*\"show\" + 0.007*\"im\" + 0.007*\"thats\" + 0.007*\"voice\"')\n",
      "(2, '0.012*\"sharane\" + 0.011*\"que\" + 0.010*\"mia\" + 0.009*\"go\" + 0.009*\"listen\" + 0.009*\"sad\" + 0.008*\"one\" + 0.008*\"12\" + 0.008*\"isso\" + 0.008*\"show\" + 0.007*\"see\" + 0.007*\"adam\"')\n",
      "(3, '0.024*\"like\" + 0.016*\"mia\" + 0.015*\"voice\" + 0.013*\"song\" + 0.010*\"jackie\" + 0.010*\"singer\" + 0.009*\"good\" + 0.009*\"america\" + 0.009*\"performance\" + 0.008*\"get\" + 0.008*\"best\" + 0.008*\"vote\"')\n",
      " \n",
      "Reid_Umstattd\n",
      " \n",
      "(0, '0.030*\"adam\" + 0.024*\"reid\" + 0.014*\"get\" + 0.013*\"well\" + 0.011*\"jackie\" + 0.009*\"one\" + 0.008*\"see\" + 0.008*\"f\" + 0.008*\"like\" + 0.008*\"wilkes\" + 0.008*\"people\" + 0.006*\"want\"')\n",
      "(1, '0.021*\"performance\" + 0.019*\"good\" + 0.016*\"actually\" + 0.016*\"adam\" + 0.013*\"season\" + 0.013*\"agree\" + 0.010*\"twitter\" + 0.010*\"vote\" + 0.009*\"stay\" + 0.007*\"one\" + 0.007*\"way\" + 0.007*\"favorite\"')\n",
      "(2, '0.027*\"adam\" + 0.025*\"voice\" + 0.023*\"reid\" + 0.019*\"go\" + 0.010*\"make\" + 0.009*\"season\" + 0.009*\"deserve\" + 0.009*\"save\" + 0.009*\"get\" + 0.009*\"hate\" + 0.008*\"jackie\" + 0.007*\"someone\"')\n",
      "(3, '0.023*\"like\" + 0.018*\"im\" + 0.018*\"guy\" + 0.009*\"sad\" + 0.009*\"sound\" + 0.009*\"deserve\" + 0.009*\"good\" + 0.009*\"really\" + 0.009*\"think\" + 0.009*\"season\" + 0.009*\"jackie\" + 0.009*\"look\"')\n",
      " \n",
      "Austin_Giorgio\n",
      " \n",
      "(0, '0.050*\"like\" + 0.011*\"round\" + 0.010*\"austin\" + 0.009*\"top\" + 0.009*\"look\" + 0.008*\"vote\" + 0.008*\"playoff\" + 0.008*\"artist\" + 0.008*\"style\" + 0.007*\"buble\" + 0.007*\"this\" + 0.007*\"12\"')\n",
      "(1, '0.038*\"song\" + 0.017*\"austin\" + 0.016*\"like\" + 0.013*\"im\" + 0.012*\"show\" + 0.011*\"sing\" + 0.010*\"he\" + 0.010*\"go\" + 0.008*\"performance\" + 0.008*\"voice\" + 0.007*\"think\" + 0.007*\"great\"')\n",
      "(2, '0.055*\"song\" + 0.022*\"choice\" + 0.020*\"good\" + 0.017*\"like\" + 0.015*\"him\" + 0.014*\"bad\" + 0.011*\"really\" + 0.011*\"well\" + 0.010*\"performance\" + 0.010*\"voice\" + 0.010*\"think\" + 0.009*\"one\"')\n",
      "(3, '0.024*\"song\" + 0.020*\"like\" + 0.017*\"sound\" + 0.017*\"buble\" + 0.017*\"make\" + 0.014*\"austin\" + 0.012*\"michael\" + 0.010*\"sing\" + 0.010*\"bieber\" + 0.009*\"get\" + 0.008*\"think\" + 0.008*\"blake\"')\n",
      " \n",
      "Gary_Edwards\n",
      " \n",
      "(0, '0.045*\"song\" + 0.031*\"like\" + 0.017*\"good\" + 0.017*\"country\" + 0.016*\"sing\" + 0.011*\"get\" + 0.010*\"really\" + 0.010*\"choice\" + 0.009*\"well\" + 0.009*\"people\" + 0.009*\"job\" + 0.008*\"much\"')\n",
      "(1, '0.044*\"song\" + 0.015*\"america\" + 0.014*\"voice\" + 0.012*\"message\" + 0.011*\"sing\" + 0.011*\"get\" + 0.011*\"choice\" + 0.010*\"perfectly\\u200b\" + 0.010*\"sung\" + 0.010*\"american\" + 0.009*\"cant\" + 0.008*\"say\"')\n",
      "(2, '0.029*\"country\" + 0.018*\"america\" + 0.015*\"world\" + 0.013*\"right\" + 0.009*\"song\" + 0.009*\"come\" + 0.008*\"gary\" + 0.008*\"even\" + 0.008*\"best\" + 0.008*\"one\" + 0.008*\"life\" + 0.007*\"get\"')\n",
      "(3, '0.017*\"like\" + 0.015*\"country\" + 0.011*\"hope\" + 0.010*\"people\" + 0.010*\"matter\" + 0.010*\"comment\" + 0.008*\"song\" + 0.008*\"race\" + 0.008*\"beautiful\" + 0.007*\"he\" + 0.007*\"say\" + 0.007*\"get\"')\n",
      " \n",
      "Spensha_Baker\n",
      " \n",
      "(0, '0.041*\"like\" + 0.033*\"song\" + 0.013*\"make\" + 0.013*\"spensha\" + 0.013*\"voice\" + 0.013*\"get\" + 0.012*\"choice\" + 0.010*\"need\" + 0.010*\"right\" + 0.010*\"season\" + 0.010*\"country\" + 0.008*\"music\"')\n",
      "(1, '0.016*\"bad\" + 0.015*\"voice\" + 0.014*\"well\" + 0.011*\"like\" + 0.011*\"gospel\" + 0.008*\"im\" + 0.008*\"sound\" + 0.008*\"always\" + 0.008*\"go\" + 0.008*\"give\" + 0.008*\"show\" + 0.008*\"sing\"')\n",
      "(2, '0.026*\"country\" + 0.022*\"spensha\" + 0.021*\"song\" + 0.017*\"voice\" + 0.016*\"girl\" + 0.014*\"think\" + 0.014*\"good\" + 0.013*\"like\" + 0.013*\"well\" + 0.012*\"sound\" + 0.011*\"blake\" + 0.010*\"would\"')\n",
      "(3, '0.022*\"like\" + 0.018*\"her\" + 0.018*\"blake\" + 0.016*\"it\" + 0.012*\"artist\" + 0.010*\"great\" + 0.010*\"voice\" + 0.010*\"put\" + 0.010*\"sing\" + 0.008*\"feel\" + 0.008*\"really\" + 0.008*\"save\"')\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilkes\n",
      " \n",
      "(0, '0.042*\"wilkes\" + 0.023*\"like\" + 0.021*\"mic\" + 0.019*\"blake\" + 0.019*\"go\" + 0.010*\"make\" + 0.010*\"vote\" + 0.010*\"great\" + 0.009*\"save\" + 0.008*\"pryor\" + 0.008*\"drop\" + 0.008*\"im\"')\n",
      "(1, '0.015*\"make\" + 0.014*\"top\" + 0.013*\"12\" + 0.012*\"think\" + 0.012*\"he\" + 0.010*\"talented\" + 0.010*\"im\" + 0.010*\"performance\" + 0.009*\"one\" + 0.009*\"last\" + 0.008*\"sing\" + 0.008*\"drop\"')\n",
      "(2, '0.022*\"like\" + 0.016*\"wilkes\" + 0.015*\"best\" + 0.014*\"performance\" + 0.014*\"get\" + 0.012*\"voice\" + 0.012*\"save\" + 0.011*\"he\" + 0.010*\"good\" + 0.009*\"well\" + 0.009*\"mic\" + 0.009*\"version\"')\n",
      "(3, '0.032*\"song\" + 0.019*\"wilkes\" + 0.017*\"really\" + 0.014*\"like\" + 0.014*\"drop\" + 0.013*\"mic\" + 0.010*\"performance\" + 0.008*\"choice\" + 0.008*\"make\" + 0.008*\"it\" + 0.007*\"gwen\" + 0.007*\"save\"')\n",
      " \n",
      "Alexa_Cappelli\n",
      " \n",
      "(0, '0.018*\"dr\" + 0.018*\"good\" + 0.014*\"like\" + 0.014*\"robbed\" + 0.013*\"alexa\" + 0.013*\"brynn\" + 0.012*\"kelly\" + 0.011*\"get\" + 0.011*\"go\" + 0.010*\"performance\" + 0.010*\"underrated\" + 0.009*\"kaleb\"')\n",
      "(1, '0.017*\"season\" + 0.017*\"like\" + 0.012*\"kaleb\" + 0.011*\"make\" + 0.010*\"song\" + 0.010*\"hear\" + 0.010*\"it\" + 0.010*\"performance\" + 0.008*\"move\" + 0.008*\"voice\" + 0.008*\"would\" + 0.008*\"people\"')\n",
      "(2, '0.051*\"song\" + 0.024*\"choice\" + 0.023*\"like\" + 0.017*\"alexa\" + 0.016*\"well\" + 0.013*\"kelly\" + 0.011*\"really\" + 0.011*\"team\" + 0.011*\"im\" + 0.010*\"people\" + 0.009*\"know\" + 0.009*\"make\"')\n",
      "(3, '0.031*\"rob\" + 0.016*\"alexa\" + 0.014*\"show\" + 0.012*\"12\" + 0.012*\"top\" + 0.010*\"dylan\" + 0.008*\"true\" + 0.008*\"know\" + 0.008*\"stage\" + 0.007*\"playoff\" + 0.007*\"sound\" + 0.007*\"get\"')\n",
      " \n",
      "D.R._King\n",
      " \n",
      "(0, '0.023*\"get\" + 0.022*\"song\" + 0.019*\"like\" + 0.017*\"kelly\" + 0.016*\"make\" + 0.016*\"choice\" + 0.014*\"good\" + 0.013*\"dr\" + 0.011*\"dylan\" + 0.011*\"kaleb\" + 0.011*\"team\" + 0.010*\"im\"')\n",
      "(1, '0.016*\"go\" + 0.016*\"dr\" + 0.013*\"sing\" + 0.013*\"deserve\" + 0.013*\"u\" + 0.013*\"watch\" + 0.013*\"like\" + 0.011*\"good\" + 0.011*\"people\" + 0.008*\"best\" + 0.008*\"see\" + 0.008*\"cant\"')\n",
      "(2, '0.032*\"dr\" + 0.021*\"like\" + 0.014*\"im\" + 0.014*\"happy\" + 0.013*\"kelly\" + 0.013*\"singer\" + 0.013*\"performance\" + 0.013*\"well\" + 0.013*\"voice\" + 0.010*\"nice\" + 0.010*\"job\" + 0.008*\"last\"')\n",
      "(3, '0.023*\"like\" + 0.021*\"dr\" + 0.017*\"king\" + 0.017*\"top\" + 0.017*\"12\" + 0.014*\"one\" + 0.011*\"make\" + 0.011*\"voice\" + 0.011*\"think\" + 0.011*\"song\" + 0.009*\"go\" + 0.009*\"contestant\"')\n",
      " \n",
      "Dylan_Hartigan\n",
      " \n",
      "(0, '0.024*\"like\" + 0.021*\"song\" + 0.021*\"dylan\" + 0.020*\"voice\" + 0.013*\"he\" + 0.012*\"petty\" + 0.012*\"tom\" + 0.010*\"make\" + 0.009*\"good\" + 0.009*\"really\" + 0.008*\"bad\" + 0.007*\"think\"')\n",
      "(1, '0.023*\"vote\" + 0.013*\"go\" + 0.012*\"think\" + 0.011*\"like\" + 0.009*\"im\" + 0.009*\"make\" + 0.008*\"top\" + 0.008*\"sexy\" + 0.008*\"home\" + 0.008*\"yes\" + 0.007*\"good\" + 0.007*\"he\"')\n",
      "(2, '0.019*\"voice\" + 0.018*\"go\" + 0.011*\"get\" + 0.011*\"dont\" + 0.011*\"sad\" + 0.010*\"good\" + 0.010*\"see\" + 0.010*\"im\" + 0.009*\"look\" + 0.009*\"kaleb\" + 0.008*\"it\" + 0.008*\"out\"')\n",
      "(3, '0.025*\"dylan\" + 0.020*\"get\" + 0.017*\"like\" + 0.014*\"well\" + 0.014*\"dr\" + 0.012*\"go\" + 0.012*\"im\" + 0.012*\"vote\" + 0.011*\"top\" + 0.010*\"kelly\" + 0.008*\"guy\" + 0.008*\"kaleb\"')\n",
      " \n",
      "Tish_Haynes_Keys\n",
      " \n",
      "(0, '0.024*\"sing\" + 0.015*\"tish\" + 0.015*\"song\" + 0.015*\"best\" + 0.013*\"go\" + 0.013*\"choice\" + 0.010*\"win\" + 0.008*\"performance\" + 0.008*\"season\" + 0.008*\"key\" + 0.008*\"haynes\" + 0.008*\"rob\"')\n",
      "(1, '0.020*\"get\" + 0.017*\"kyla\" + 0.015*\"top\" + 0.014*\"12\" + 0.013*\"kaleb\" + 0.012*\"good\" + 0.011*\"it\" + 0.011*\"go\" + 0.010*\"singer\" + 0.010*\"jackie\" + 0.010*\"performance\" + 0.010*\"kelly\"')\n",
      "(2, '0.016*\"kyla\" + 0.016*\"like\" + 0.015*\"note\" + 0.014*\"america\" + 0.013*\"go\" + 0.009*\"big\" + 0.009*\"jackie\" + 0.009*\"season\" + 0.009*\"voice\" + 0.008*\"country\" + 0.008*\"christiana\" + 0.008*\"show\"')\n",
      "(3, '0.018*\"song\" + 0.017*\"like\" + 0.017*\"good\" + 0.016*\"voice\" + 0.012*\"many\" + 0.011*\"singer\" + 0.011*\"great\" + 0.011*\"robbed\" + 0.009*\"pitchy\" + 0.009*\"beautiful\" + 0.008*\"it\" + 0.007*\"sound\"')\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Adam_Levine=['Drew_Cole','Jackie_Verna','Mia_Boostrom','Reid_Umstattd']\n",
    "Alicia_Keys=['Johnny_Bliss','Christiana_Danielle','Kelsea_Johnson','Terrence_Cunningham']\n",
    "Blake_Shelton=['Austin_Giorgio','Gary_Edwards','Spensha_Baker','Wilkes']\n",
    "Kelly_Clarkson=['Alexa_Cappelli','D.R._King','Dylan_Hartigan','Tish_Haynes_Keys']\n",
    "experts={'Alicia_Keys':Alicia_Keys,'Adam_Levine':Adam_Levine,'Blake_Shelton':Blake_Shelton,'Kelly_Clarkson':Kelly_Clarkson}\n",
    "for key,value in experts.items():\n",
    "   \n",
    "        \n",
    "    for i in range(len(value)):\n",
    "        data=pd.read_csv(r'C:\\Users\\zgh\\Downloads\\text final\\{}\\{}.csv'.format(key,value[i]))\n",
    "        stop = set(stopwords.words('english'))\n",
    "        exclude = set(string.punctuation) \n",
    "        lemma = WordNetLemmatizer()\n",
    "        frames = [data['commentText'][pd.notna(data['commentText'])], \\\n",
    "                  data['replies.commentText'][pd.notna(data['replies.commentText'])]]\n",
    "        datanona=pd.concat(frames)\n",
    "        \n",
    "        def clean(doc):\n",
    "            stop_free = \" \".join([i for i in str(doc).lower().split() if i not in stop])\n",
    "            punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "            other_punc_free=''.join(ch for ch in punc_free if ch!='’')\n",
    "            normalized = \" \".join(lemma.lemmatize(word) for word in other_punc_free.split())\n",
    "            replacelove=normalized.replace('love','like')\n",
    "            pos_tagging_without_stopwords=nltk.pos_tag(replacelove.split())\n",
    "            def get_wordnet_pos(treebank_tag):\n",
    "                if treebank_tag.startswith('J'):\n",
    "                    return wordnet.ADJ\n",
    "                elif treebank_tag.startswith('V'):\n",
    "                    return wordnet.VERB\n",
    "                elif treebank_tag.startswith('N'):\n",
    "                    return wordnet.NOUN\n",
    "                elif treebank_tag.startswith('R'):\n",
    "                    return wordnet.ADV\n",
    "                else:\n",
    "                    return None\n",
    "            l=[]\n",
    "            for word, tag in pos_tagging_without_stopwords:\n",
    "                wntag = get_wordnet_pos(tag)\n",
    "                if wntag is None:\n",
    "                    lemma1 = lemma.lemmatize(word)\n",
    "                    l.append(lemma1)\n",
    "                else:\n",
    "                    lemma1 = lemma.lemmatize(word, pos=wntag) \n",
    "                    l.append(lemma1)\n",
    "            return ' '.join(l)\n",
    "        datacom=datanona.map(clean)\n",
    "        datacomtoken=datacom.map(word_tokenize)\n",
    "        id2word = corpora.Dictionary(datacomtoken)\n",
    "        corpus=[id2word.doc2bow(text) for text in datacomtoken]\n",
    "\n",
    "        NUM_TOPICS = 4\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=id2word, passes=15)\n",
    "        topics = ldamodel.print_topics(num_words=12)\n",
    "        print (value[i])\n",
    "        print(' ')\n",
    "        #vis_data = gensimvis.prepare(ldamodel, corpus, id2word)\n",
    "        #pyLDAvis.display(vis_data)\n",
    "        for topic in topics:\n",
    "            print(topic)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnny_Bliss\n",
      " \n",
      "(0, '0.028*\"song\" + 0.021*\"like\" + 0.016*\"sing\" + 0.014*\"artist\" + 0.013*\"well\" + 0.012*\"kelsea\" + 0.010*\"playoff\" + 0.010*\"alicia\" + 0.009*\"jackie\" + 0.008*\"one\" + 0.008*\"adele\" + 0.008*\"christiana\"')\n",
      "(1, '0.023*\"go\" + 0.022*\"like\" + 0.019*\"good\" + 0.014*\"voice\" + 0.012*\"johnny\" + 0.012*\"song\" + 0.010*\"think\" + 0.010*\"him\" + 0.010*\"performance\" + 0.008*\"top\" + 0.008*\"im\" + 0.008*\"favorite\"')\n",
      "(2, '0.031*\"like\" + 0.025*\"song\" + 0.016*\"really\" + 0.015*\"get\" + 0.014*\"performance\" + 0.014*\"good\" + 0.011*\"voice\" + 0.011*\"team\" + 0.009*\"3\" + 0.009*\"sing\" + 0.008*\"well\" + 0.008*\"would\"')\n",
      " \n",
      "Christiana_Danielle\n",
      " \n",
      "(0, '0.017*\"christiana\" + 0.015*\"performance\" + 0.013*\"voice\" + 0.013*\"top\" + 0.011*\"get\" + 0.010*\"12\" + 0.009*\"like\" + 0.009*\"go\" + 0.008*\"jackie\" + 0.007*\"win\" + 0.007*\"best\" + 0.006*\"alicia\"')\n",
      "(1, '0.038*\"like\" + 0.024*\"song\" + 0.012*\"make\" + 0.010*\"christiana\" + 0.009*\"voice\" + 0.008*\"good\" + 0.008*\"well\" + 0.008*\"sing\" + 0.008*\"go\" + 0.008*\"performance\" + 0.008*\"note\" + 0.007*\"one\"')\n",
      "(2, '0.021*\"alicia\" + 0.018*\"im\" + 0.011*\"save\" + 0.010*\"get\" + 0.010*\"omg\" + 0.010*\"win\" + 0.010*\"christiana\" + 0.010*\"good\" + 0.010*\"vote\" + 0.009*\"her\" + 0.009*\"voice\" + 0.008*\"jackie\"')\n",
      " \n",
      "Kelsea_Johnson\n",
      " \n",
      "(0, '0.062*\"kelsea\" + 0.029*\"like\" + 0.021*\"voice\" + 0.021*\"make\" + 0.018*\"alicia\" + 0.015*\"team\" + 0.013*\"top\" + 0.012*\"christiana\" + 0.012*\"one\" + 0.011*\"hope\" + 0.010*\"hill\" + 0.009*\"12\"')\n",
      "(1, '0.034*\"like\" + 0.014*\"voice\" + 0.011*\"go\" + 0.010*\"song\" + 0.009*\"lauryn\" + 0.009*\"hill\" + 0.008*\"unique\" + 0.008*\"im\" + 0.006*\"would\" + 0.006*\"didnt\" + 0.006*\"really\" + 0.006*\"perfect\"')\n",
      "(2, '0.024*\"song\" + 0.015*\"good\" + 0.011*\"like\" + 0.011*\"choice\" + 0.009*\"know\" + 0.008*\"sing\" + 0.008*\"show\" + 0.008*\"need\" + 0.008*\"note\" + 0.007*\"go\" + 0.007*\"well\" + 0.007*\"great\"')\n",
      " \n",
      "Terrence_Cunningham\n",
      " \n",
      "(0, '0.013*\"im\" + 0.010*\"he\" + 0.009*\"go\" + 0.009*\"christiana\" + 0.008*\"performance\" + 0.007*\"good\" + 0.007*\"see\" + 0.007*\"well\" + 0.006*\"sarayah\" + 0.006*\"favorite\" + 0.006*\"bore\" + 0.005*\"one\"')\n",
      "(1, '0.020*\"like\" + 0.013*\"piano\" + 0.012*\"voice\" + 0.012*\"song\" + 0.011*\"make\" + 0.011*\"show\" + 0.010*\"artist\" + 0.010*\"terrence\" + 0.009*\"one\" + 0.009*\"get\" + 0.008*\"music\" + 0.008*\"people\"')\n",
      "(2, '0.025*\"like\" + 0.019*\"get\" + 0.010*\"piano\" + 0.010*\"he\" + 0.010*\"performance\" + 0.009*\"think\" + 0.008*\"alicia\" + 0.008*\"terrence\" + 0.008*\"voice\" + 0.007*\"feel\" + 0.007*\"something\" + 0.007*\"good\"')\n",
      " \n",
      "Drew_Cole\n",
      " \n",
      "(0, '0.024*\"country\" + 0.017*\"adam\" + 0.014*\"make\" + 0.011*\"really\" + 0.011*\"favorite\" + 0.010*\"wilkes\" + 0.009*\"season\" + 0.009*\"thank\" + 0.008*\"song\" + 0.008*\"draw\" + 0.008*\"artist\" + 0.007*\"music\"')\n",
      "(1, '0.025*\"go\" + 0.020*\"voice\" + 0.019*\"song\" + 0.015*\"adam\" + 0.013*\"like\" + 0.013*\"draw\" + 0.012*\"really\" + 0.011*\"one\" + 0.010*\"drew\" + 0.009*\"jackie\" + 0.008*\"well\" + 0.008*\"he\"')\n",
      "(2, '0.014*\"jackie\" + 0.012*\"adam\" + 0.012*\"well\" + 0.009*\"like\" + 0.009*\"wrong\" + 0.009*\"top\" + 0.009*\"country\" + 0.009*\"im\" + 0.009*\"choose\" + 0.008*\"drew\" + 0.008*\"team\" + 0.007*\"sing\"')\n",
      " \n",
      "Jackie_Verna\n",
      " \n",
      "(0, '0.020*\"like\" + 0.018*\"adam\" + 0.017*\"think\" + 0.016*\"make\" + 0.015*\"jackie\" + 0.013*\"performance\" + 0.013*\"get\" + 0.010*\"mia\" + 0.009*\"top\" + 0.008*\"good\" + 0.008*\"one\" + 0.008*\"go\"')\n",
      "(1, '0.033*\"jackie\" + 0.019*\"mia\" + 0.018*\"reid\" + 0.014*\"song\" + 0.012*\"adam\" + 0.012*\"like\" + 0.009*\"go\" + 0.008*\"good\" + 0.008*\"im\" + 0.008*\"singer\" + 0.008*\"say\" + 0.008*\"choice\"')\n",
      "(2, '0.016*\"adam\" + 0.014*\"like\" + 0.013*\"jackie\" + 0.012*\"country\" + 0.010*\"song\" + 0.010*\"go\" + 0.010*\"season\" + 0.009*\"voice\" + 0.009*\"well\" + 0.008*\"show\" + 0.008*\"last\" + 0.008*\"bad\"')\n",
      " \n",
      "Mia_Boostrom\n",
      " \n",
      "(0, '0.015*\"performance\" + 0.012*\"good\" + 0.010*\"like\" + 0.009*\"que\" + 0.009*\"even\" + 0.008*\"show\" + 0.008*\"singer\" + 0.008*\"brynn\" + 0.007*\"im\" + 0.007*\"na\" + 0.007*\"isso\" + 0.006*\"one\"')\n",
      "(1, '0.016*\"song\" + 0.013*\"note\" + 0.013*\"voice\" + 0.011*\"like\" + 0.010*\"good\" + 0.010*\"really\" + 0.009*\"cant\" + 0.009*\"go\" + 0.008*\"use\" + 0.008*\"hit\" + 0.007*\"sing\" + 0.006*\"singer\"')\n",
      "(2, '0.026*\"mia\" + 0.025*\"like\" + 0.014*\"song\" + 0.013*\"bad\" + 0.012*\"performance\" + 0.011*\"one\" + 0.011*\"jackie\" + 0.010*\"voice\" + 0.010*\"great\" + 0.009*\"would\" + 0.009*\"it\" + 0.008*\"adam\"')\n",
      " \n",
      "Reid_Umstattd\n",
      " \n",
      "(0, '0.022*\"jackie\" + 0.018*\"reid\" + 0.014*\"deserve\" + 0.012*\"adam\" + 0.010*\"like\" + 0.010*\"vote\" + 0.010*\"go\" + 0.010*\"well\" + 0.009*\"actually\" + 0.008*\"im\" + 0.008*\"rayshun\" + 0.008*\"song\"')\n",
      "(1, '0.018*\"really\" + 0.017*\"adam\" + 0.014*\"voice\" + 0.010*\"team\" + 0.009*\"britton\" + 0.009*\"season\" + 0.009*\"great\" + 0.008*\"like\" + 0.007*\"system\" + 0.007*\"lose\" + 0.007*\"good\" + 0.007*\"bad\"')\n",
      "(2, '0.032*\"adam\" + 0.020*\"reid\" + 0.016*\"go\" + 0.014*\"voice\" + 0.013*\"performance\" + 0.012*\"get\" + 0.010*\"make\" + 0.010*\"good\" + 0.009*\"season\" + 0.009*\"he\" + 0.009*\"one\" + 0.008*\"watch\"')\n",
      " \n",
      "Austin_Giorgio\n",
      " \n",
      "(0, '0.046*\"song\" + 0.017*\"choice\" + 0.013*\"good\" + 0.011*\"sing\" + 0.011*\"think\" + 0.010*\"get\" + 0.009*\"make\" + 0.009*\"well\" + 0.009*\"blake\" + 0.008*\"bad\" + 0.008*\"show\" + 0.008*\"artist\"')\n",
      "(1, '0.018*\"austin\" + 0.016*\"like\" + 0.014*\"song\" + 0.012*\"best\" + 0.011*\"performance\" + 0.010*\"great\" + 0.010*\"turtleneck\" + 0.009*\"him\" + 0.009*\"think\" + 0.009*\"this\" + 0.009*\"look\" + 0.009*\"go\"')\n",
      "(2, '0.053*\"like\" + 0.027*\"song\" + 0.019*\"buble\" + 0.016*\"sound\" + 0.014*\"michael\" + 0.011*\"austin\" + 0.010*\"go\" + 0.009*\"good\" + 0.009*\"bieber\" + 0.009*\"he\" + 0.008*\"im\" + 0.008*\"make\"')\n",
      " \n",
      "Gary_Edwards\n",
      " \n",
      "(0, '0.033*\"song\" + 0.027*\"like\" + 0.014*\"get\" + 0.013*\"country\" + 0.013*\"good\" + 0.012*\"choice\" + 0.009*\"people\" + 0.008*\"blake\" + 0.008*\"gary\" + 0.008*\"see\" + 0.007*\"it\" + 0.006*\"know\"')\n",
      "(1, '0.023*\"song\" + 0.022*\"country\" + 0.010*\"right\" + 0.010*\"america\" + 0.009*\"think\" + 0.009*\"world\" + 0.008*\"one\" + 0.008*\"say\" + 0.008*\"like\" + 0.008*\"best\" + 0.007*\"well\" + 0.007*\"sing\"')\n",
      "(2, '0.031*\"song\" + 0.021*\"america\" + 0.014*\"message\" + 0.014*\"voice\" + 0.014*\"sing\" + 0.013*\"sung\" + 0.012*\"beautiful\" + 0.011*\"american\" + 0.011*\"perfectly\\u200b\" + 0.008*\"cant\" + 0.008*\"get\" + 0.007*\"im\"')\n",
      " \n",
      "Spensha_Baker\n",
      " \n",
      "(0, '0.027*\"song\" + 0.021*\"voice\" + 0.020*\"country\" + 0.019*\"like\" + 0.012*\"choice\" + 0.010*\"good\" + 0.010*\"spensha\" + 0.010*\"her\" + 0.010*\"sound\" + 0.009*\"think\" + 0.009*\"go\" + 0.009*\"feel\"')\n",
      "(1, '0.027*\"like\" + 0.014*\"voice\" + 0.012*\"country\" + 0.011*\"make\" + 0.008*\"well\" + 0.008*\"artist\" + 0.008*\"music\" + 0.008*\"song\" + 0.008*\"think\" + 0.007*\"im\" + 0.007*\"bad\" + 0.007*\"performance\"')\n",
      "(2, '0.022*\"like\" + 0.020*\"song\" + 0.020*\"spensha\" + 0.018*\"girl\" + 0.018*\"blake\" + 0.013*\"need\" + 0.013*\"good\" + 0.013*\"well\" + 0.012*\"it\" + 0.010*\"her\" + 0.010*\"carrie\" + 0.009*\"country\"')\n",
      " \n",
      "Wilkes\n",
      " \n",
      "(0, '0.020*\"performance\" + 0.018*\"song\" + 0.016*\"wilkes\" + 0.016*\"he\" + 0.013*\"save\" + 0.013*\"like\" + 0.011*\"mic\" + 0.011*\"best\" + 0.011*\"get\" + 0.011*\"voice\" + 0.010*\"really\" + 0.009*\"make\"')\n",
      "(1, '0.029*\"wilkes\" + 0.015*\"like\" + 0.014*\"go\" + 0.011*\"make\" + 0.010*\"vote\" + 0.009*\"talented\" + 0.008*\"cant\" + 0.008*\"song\" + 0.008*\"it\" + 0.008*\"one\" + 0.007*\"blake\" + 0.007*\"show\"')\n",
      "(2, '0.026*\"mic\" + 0.023*\"like\" + 0.020*\"drop\" + 0.020*\"wilkes\" + 0.012*\"good\" + 0.010*\"go\" + 0.010*\"think\" + 0.009*\"make\" + 0.009*\"song\" + 0.009*\"voice\" + 0.008*\"blake\" + 0.008*\"really\"')\n",
      " \n",
      "Alexa_Cappelli\n",
      " \n",
      "(0, '0.026*\"song\" + 0.015*\"like\" + 0.012*\"choice\" + 0.011*\"kaleb\" + 0.011*\"well\" + 0.010*\"go\" + 0.009*\"alexa\" + 0.008*\"rob\" + 0.008*\"underrated\" + 0.008*\"hope\" + 0.008*\"kelly\" + 0.007*\"would\"')\n",
      "(1, '0.014*\"alexa\" + 0.012*\"song\" + 0.011*\"make\" + 0.011*\"season\" + 0.011*\"really\" + 0.010*\"brynn\" + 0.010*\"think\" + 0.009*\"show\" + 0.009*\"top\" + 0.009*\"12\" + 0.009*\"voice\" + 0.008*\"know\"')\n",
      "(2, '0.027*\"like\" + 0.022*\"song\" + 0.016*\"alexa\" + 0.015*\"rob\" + 0.013*\"good\" + 0.013*\"kelly\" + 0.013*\"get\" + 0.012*\"im\" + 0.011*\"move\" + 0.011*\"robbed\" + 0.011*\"people\" + 0.010*\"dr\"')\n",
      " \n",
      "D.R._King\n",
      " \n",
      "(0, '0.014*\"kelly\" + 0.014*\"top\" + 0.014*\"12\" + 0.013*\"like\" + 0.011*\"im\" + 0.011*\"you\" + 0.009*\"good\" + 0.009*\"last\" + 0.009*\"singer\" + 0.009*\"song\" + 0.007*\"show\" + 0.007*\"know\"')\n",
      "(1, '0.036*\"like\" + 0.014*\"make\" + 0.011*\"song\" + 0.011*\"get\" + 0.011*\"go\" + 0.011*\"see\" + 0.010*\"voice\" + 0.010*\"season\" + 0.009*\"king\" + 0.008*\"kaleb\" + 0.008*\"one\" + 0.008*\"dr\"')\n",
      "(2, '0.049*\"dr\" + 0.016*\"deserve\" + 0.015*\"well\" + 0.014*\"kelly\" + 0.014*\"song\" + 0.013*\"save\" + 0.012*\"team\" + 0.012*\"good\" + 0.011*\"king\" + 0.011*\"choice\" + 0.010*\"dylan\" + 0.008*\"like\"')\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dylan_Hartigan\n",
      " \n",
      "(0, '0.022*\"go\" + 0.022*\"voice\" + 0.016*\"like\" + 0.009*\"one\" + 0.009*\"dylan\" + 0.008*\"really\" + 0.008*\"think\" + 0.007*\"he\" + 0.007*\"deserve\" + 0.007*\"cant\" + 0.007*\"see\" + 0.007*\"best\"')\n",
      "(1, '0.017*\"get\" + 0.016*\"he\" + 0.015*\"like\" + 0.013*\"vote\" + 0.012*\"top\" + 0.009*\"didnt\" + 0.009*\"good\" + 0.008*\"make\" + 0.008*\"kelly\" + 0.008*\"really\" + 0.007*\"voice\" + 0.007*\"it\"')\n",
      "(2, '0.030*\"dylan\" + 0.016*\"im\" + 0.015*\"song\" + 0.012*\"kaleb\" + 0.012*\"like\" + 0.011*\"vote\" + 0.010*\"well\" + 0.010*\"dr\" + 0.010*\"choice\" + 0.010*\"make\" + 0.009*\"it\" + 0.009*\"good\"')\n",
      " \n",
      "Tish_Haynes_Keys\n",
      " \n",
      "(0, '0.015*\"season\" + 0.014*\"get\" + 0.012*\"jackie\" + 0.012*\"team\" + 0.011*\"best\" + 0.011*\"kyla\" + 0.010*\"kaleb\" + 0.009*\"think\" + 0.009*\"good\" + 0.009*\"christiana\" + 0.009*\"singer\" + 0.008*\"kelly\"')\n",
      "(1, '0.015*\"song\" + 0.011*\"get\" + 0.011*\"robbed\" + 0.010*\"big\" + 0.010*\"america\" + 0.009*\"say\" + 0.008*\"performance\" + 0.008*\"kyla\" + 0.008*\"well\" + 0.008*\"make\" + 0.008*\"good\" + 0.008*\"sad\"')\n",
      "(2, '0.019*\"go\" + 0.017*\"like\" + 0.014*\"kyla\" + 0.013*\"voice\" + 0.013*\"song\" + 0.012*\"good\" + 0.012*\"sing\" + 0.011*\"tish\" + 0.009*\"country\" + 0.009*\"singer\" + 0.008*\"im\" + 0.008*\"last\"')\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Adam_Levine=['Drew_Cole','Jackie_Verna','Mia_Boostrom','Reid_Umstattd']\n",
    "Alicia_Keys=['Johnny_Bliss','Christiana_Danielle','Kelsea_Johnson','Terrence_Cunningham']\n",
    "Blake_Shelton=['Austin_Giorgio','Gary_Edwards','Spensha_Baker','Wilkes']\n",
    "Kelly_Clarkson=['Alexa_Cappelli','D.R._King','Dylan_Hartigan','Tish_Haynes_Keys']\n",
    "experts={'Alicia_Keys':Alicia_Keys,'Adam_Levine':Adam_Levine,'Blake_Shelton':Blake_Shelton,'Kelly_Clarkson':Kelly_Clarkson}\n",
    "for key,value in experts.items():\n",
    "   \n",
    "        \n",
    "    for i in range(len(value)):\n",
    "        data=pd.read_csv(r'C:\\Users\\zgh\\Downloads\\text final\\{}\\{}.csv'.format(key,value[i]))\n",
    "        stop = set(stopwords.words('english'))\n",
    "        exclude = set(string.punctuation) \n",
    "        lemma = WordNetLemmatizer()\n",
    "        frames = [data['commentText'][pd.notna(data['commentText'])], \\\n",
    "                  data['replies.commentText'][pd.notna(data['replies.commentText'])]]\n",
    "        datanona=pd.concat(frames)\n",
    "    \n",
    "        def clean(doc):\n",
    "            stop_free = \" \".join([i for i in str(doc).lower().split() if i not in stop])\n",
    "            punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "            other_punc_free=''.join(ch for ch in punc_free if ch!='’')\n",
    "            normalized = \" \".join(lemma.lemmatize(word) for word in other_punc_free.split())\n",
    "            replacelove=normalized.replace('love','like')\n",
    "            pos_tagging_without_stopwords=nltk.pos_tag(replacelove.split())\n",
    "            def get_wordnet_pos(treebank_tag):\n",
    "                if treebank_tag.startswith('J'):\n",
    "                    return wordnet.ADJ\n",
    "                elif treebank_tag.startswith('V'):\n",
    "                    return wordnet.VERB\n",
    "                elif treebank_tag.startswith('N'):\n",
    "                    return wordnet.NOUN\n",
    "                elif treebank_tag.startswith('R'):\n",
    "                    return wordnet.ADV\n",
    "                else:\n",
    "                    return None\n",
    "            l=[]\n",
    "            for word, tag in pos_tagging_without_stopwords:\n",
    "                wntag = get_wordnet_pos(tag)\n",
    "                if wntag is None:\n",
    "                    lemma1 = lemma.lemmatize(word)\n",
    "                    l.append(lemma1)\n",
    "                else:\n",
    "                    lemma1 = lemma.lemmatize(word, pos=wntag) \n",
    "                    l.append(lemma1)\n",
    "            return ' '.join(l)\n",
    "        datacom=datanona.map(clean)\n",
    "        datacomtoken=datacom.map(word_tokenize)\n",
    "        id2word = corpora.Dictionary(datacomtoken)\n",
    "        corpus=[id2word.doc2bow(text) for text in datacomtoken]\n",
    "\n",
    "        NUM_TOPICS = 3\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=id2word, passes=15)\n",
    "        topics = ldamodel.print_topics(num_words=12)\n",
    "        print (value[i])\n",
    "        print(' ')\n",
    "        #vis_data = gensimvis.prepare(ldamodel, corpus, id2word)\n",
    "        #pyLDAvis.display(vis_data)\n",
    "        for topic in topics:\n",
    "            print(topic)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alicia_Keys Johnny_Bliss\n",
      " \n",
      "(0, '0.014*\"go\" + 0.014*\"great\" + 0.013*\"good\" + 0.011*\"like\" + 0.008*\"him\" + 0.007*\"sing\" + 0.007*\"performance\" + 0.007*\"l\" + 0.006*\"way\" + 0.006*\"singer\" + 0.006*\"a\" + 0.006*\"think\"')\n",
      "(1, '0.034*\"like\" + 0.032*\"song\" + 0.014*\"really\" + 0.012*\"voice\" + 0.011*\"sing\" + 0.011*\"good\" + 0.010*\"performance\" + 0.010*\"well\" + 0.009*\"get\" + 0.009*\"johnny\" + 0.008*\"go\" + 0.008*\"adele\"')\n",
      " \n",
      "Alicia_Keys Christiana_Danielle\n",
      " \n",
      "(0, '0.031*\"like\" + 0.017*\"song\" + 0.009*\"performance\" + 0.009*\"good\" + 0.009*\"girl\" + 0.008*\"one\" + 0.008*\"voice\" + 0.007*\"win\" + 0.006*\"sound\" + 0.006*\"sing\" + 0.006*\"queen\" + 0.005*\"it\"')\n",
      "(1, '0.019*\"christiana\" + 0.014*\"alicia\" + 0.013*\"like\" + 0.012*\"voice\" + 0.011*\"get\" + 0.011*\"go\" + 0.010*\"song\" + 0.010*\"im\" + 0.010*\"jackie\" + 0.009*\"performance\" + 0.009*\"well\" + 0.008*\"know\"')\n",
      " \n",
      "Alicia_Keys Kelsea_Johnson\n",
      " \n",
      "(0, '0.053*\"kelsea\" + 0.022*\"voice\" + 0.020*\"like\" + 0.017*\"make\" + 0.013*\"hill\" + 0.012*\"alicia\" + 0.011*\"lauryn\" + 0.011*\"team\" + 0.011*\"top\" + 0.010*\"christiana\" + 0.009*\"song\" + 0.009*\"think\"')\n",
      "(1, '0.032*\"like\" + 0.016*\"song\" + 0.015*\"good\" + 0.013*\"go\" + 0.010*\"best\" + 0.010*\"well\" + 0.008*\"show\" + 0.008*\"shes\" + 0.008*\"sound\" + 0.008*\"one\" + 0.008*\"alicia\" + 0.007*\"voice\"')\n",
      " \n",
      "Alicia_Keys Terrence_Cunningham\n",
      " \n",
      "(0, '0.014*\"like\" + 0.011*\"get\" + 0.010*\"voice\" + 0.008*\"think\" + 0.007*\"show\" + 0.007*\"terrence\" + 0.007*\"alicia\" + 0.007*\"people\" + 0.007*\"song\" + 0.006*\"artist\" + 0.006*\"know\" + 0.006*\"him\"')\n",
      "(1, '0.021*\"like\" + 0.013*\"piano\" + 0.011*\"get\" + 0.011*\"he\" + 0.010*\"go\" + 0.009*\"performance\" + 0.009*\"im\" + 0.008*\"one\" + 0.008*\"terrence\" + 0.007*\"voice\" + 0.007*\"see\" + 0.007*\"song\"')\n",
      " \n",
      "Adam_Levine Drew_Cole\n",
      " \n",
      "(0, '0.021*\"adam\" + 0.016*\"country\" + 0.014*\"well\" + 0.013*\"drew\" + 0.013*\"go\" + 0.012*\"song\" + 0.012*\"jackie\" + 0.010*\"season\" + 0.009*\"like\" + 0.009*\"team\" + 0.009*\"one\" + 0.008*\"really\"')\n",
      "(1, '0.015*\"go\" + 0.014*\"voice\" + 0.013*\"draw\" + 0.010*\"song\" + 0.010*\"make\" + 0.010*\"im\" + 0.009*\"music\" + 0.009*\"like\" + 0.009*\"jackie\" + 0.009*\"really\" + 0.009*\"adam\" + 0.007*\"favorite\"')\n",
      " \n",
      "Adam_Levine Jackie_Verna\n",
      " \n",
      "(0, '0.019*\"like\" + 0.017*\"adam\" + 0.016*\"country\" + 0.011*\"voice\" + 0.011*\"singer\" + 0.011*\"get\" + 0.010*\"jackie\" + 0.010*\"think\" + 0.009*\"song\" + 0.009*\"season\" + 0.007*\"win\" + 0.007*\"good\"')\n",
      "(1, '0.030*\"jackie\" + 0.019*\"mia\" + 0.016*\"reid\" + 0.014*\"adam\" + 0.012*\"like\" + 0.012*\"make\" + 0.011*\"well\" + 0.011*\"im\" + 0.011*\"song\" + 0.010*\"top\" + 0.010*\"go\" + 0.010*\"choice\"')\n",
      " \n",
      "Adam_Levine Mia_Boostrom\n",
      " \n",
      "(0, '0.027*\"like\" + 0.019*\"performance\" + 0.013*\"song\" + 0.011*\"bad\" + 0.008*\"voice\" + 0.008*\"really\" + 0.007*\"note\" + 0.007*\"go\" + 0.007*\"one\" + 0.006*\"im\" + 0.006*\"season\" + 0.006*\"mias\"')\n",
      "(1, '0.021*\"mia\" + 0.011*\"jackie\" + 0.011*\"song\" + 0.009*\"singer\" + 0.009*\"adam\" + 0.009*\"like\" + 0.008*\"it\" + 0.008*\"voice\" + 0.008*\"one\" + 0.007*\"great\" + 0.007*\"good\" + 0.006*\"sharane\"')\n",
      " \n",
      "Adam_Levine Reid_Umstattd\n",
      " \n",
      "(0, '0.017*\"adam\" + 0.017*\"go\" + 0.012*\"guy\" + 0.012*\"like\" + 0.010*\"good\" + 0.010*\"make\" + 0.010*\"he\" + 0.009*\"im\" + 0.008*\"sound\" + 0.008*\"well\" + 0.008*\"jackie\" + 0.008*\"sad\"')\n",
      "(1, '0.025*\"adam\" + 0.022*\"reid\" + 0.017*\"voice\" + 0.011*\"performance\" + 0.011*\"get\" + 0.010*\"deserve\" + 0.010*\"one\" + 0.009*\"jackie\" + 0.009*\"season\" + 0.008*\"vote\" + 0.008*\"twitter\" + 0.008*\"really\"')\n",
      " \n",
      "Blake_Shelton Austin_Giorgio\n",
      " \n",
      "(0, '0.034*\"like\" + 0.025*\"song\" + 0.016*\"austin\" + 0.012*\"buble\" + 0.011*\"sound\" + 0.011*\"good\" + 0.011*\"choice\" + 0.010*\"performance\" + 0.010*\"think\" + 0.009*\"michael\" + 0.008*\"blake\" + 0.008*\"him\"')\n",
      "(1, '0.039*\"song\" + 0.013*\"like\" + 0.010*\"sing\" + 0.009*\"he\" + 0.009*\"voice\" + 0.008*\"im\" + 0.008*\"bieber\" + 0.008*\"go\" + 0.008*\"sinatra\" + 0.008*\"man\" + 0.008*\"well\" + 0.007*\"show\"')\n",
      " \n",
      "Blake_Shelton Gary_Edwards\n",
      " \n",
      "(0, '0.042*\"song\" + 0.018*\"like\" + 0.015*\"sing\" + 0.011*\"choice\" + 0.011*\"voice\" + 0.009*\"get\" + 0.009*\"well\" + 0.008*\"gary\" + 0.007*\"vote\" + 0.007*\"good\" + 0.006*\"last\" + 0.006*\"show\"')\n",
      "(1, '0.027*\"country\" + 0.019*\"america\" + 0.014*\"song\" + 0.012*\"american\" + 0.012*\"world\" + 0.011*\"like\" + 0.009*\"message\" + 0.009*\"get\" + 0.008*\"people\" + 0.008*\"sung\" + 0.007*\"good\" + 0.007*\"cant\"')\n",
      " \n",
      "Blake_Shelton Spensha_Baker\n",
      " \n",
      "(0, '0.017*\"country\" + 0.017*\"song\" + 0.014*\"voice\" + 0.013*\"her\" + 0.013*\"like\" + 0.011*\"blake\" + 0.009*\"hope\" + 0.008*\"get\" + 0.008*\"carrie\" + 0.008*\"girl\" + 0.008*\"sing\" + 0.007*\"put\"')\n",
      "(1, '0.029*\"like\" + 0.019*\"song\" + 0.017*\"spensha\" + 0.014*\"voice\" + 0.012*\"country\" + 0.010*\"think\" + 0.010*\"make\" + 0.010*\"good\" + 0.010*\"well\" + 0.009*\"need\" + 0.009*\"it\" + 0.009*\"sound\"')\n",
      " \n",
      "Blake_Shelton Wilkes\n",
      " \n",
      "(0, '0.027*\"wilkes\" + 0.014*\"good\" + 0.012*\"like\" + 0.012*\"voice\" + 0.010*\"go\" + 0.009*\"performance\" + 0.009*\"song\" + 0.009*\"mic\" + 0.008*\"he\" + 0.008*\"one\" + 0.008*\"vote\" + 0.008*\"save\"')\n",
      "(1, '0.021*\"like\" + 0.017*\"wilkes\" + 0.017*\"mic\" + 0.014*\"song\" + 0.014*\"make\" + 0.012*\"blake\" + 0.011*\"drop\" + 0.009*\"performance\" + 0.009*\"top\" + 0.009*\"think\" + 0.009*\"save\" + 0.008*\"really\"')\n",
      " \n",
      "Kelly_Clarkson Alexa_Cappelli\n",
      " \n",
      "(0, '0.026*\"like\" + 0.018*\"song\" + 0.013*\"rob\" + 0.013*\"alexa\" + 0.011*\"im\" + 0.010*\"would\" + 0.009*\"good\" + 0.009*\"choice\" + 0.009*\"people\" + 0.009*\"best\" + 0.008*\"see\" + 0.008*\"robbed\"')\n",
      "(1, '0.021*\"song\" + 0.014*\"alexa\" + 0.013*\"kelly\" + 0.011*\"kaleb\" + 0.010*\"performance\" + 0.009*\"really\" + 0.008*\"team\" + 0.008*\"dr\" + 0.008*\"go\" + 0.008*\"voice\" + 0.008*\"season\" + 0.007*\"make\"')\n",
      " \n",
      "Kelly_Clarkson D.R._King\n",
      " \n",
      "(0, '0.027*\"dr\" + 0.022*\"song\" + 0.013*\"king\" + 0.013*\"kelly\" + 0.013*\"12\" + 0.013*\"top\" + 0.012*\"happy\" + 0.010*\"choice\" + 0.010*\"well\" + 0.009*\"singer\" + 0.008*\"make\" + 0.007*\"im\"')\n",
      "(1, '0.032*\"like\" + 0.014*\"get\" + 0.014*\"dr\" + 0.014*\"go\" + 0.012*\"good\" + 0.012*\"voice\" + 0.009*\"make\" + 0.009*\"deserve\" + 0.009*\"kelly\" + 0.009*\"save\" + 0.008*\"one\" + 0.008*\"think\"')\n",
      " \n",
      "Kelly_Clarkson Dylan_Hartigan\n",
      " \n",
      "(0, '0.019*\"go\" + 0.017*\"dylan\" + 0.014*\"vote\" + 0.013*\"im\" + 0.011*\"get\" + 0.011*\"well\" + 0.010*\"good\" + 0.010*\"song\" + 0.009*\"top\" + 0.009*\"think\" + 0.008*\"kelly\" + 0.007*\"see\"')\n",
      "(1, '0.022*\"like\" + 0.017*\"voice\" + 0.013*\"dylan\" + 0.010*\"he\" + 0.009*\"it\" + 0.009*\"dont\" + 0.008*\"make\" + 0.008*\"look\" + 0.008*\"get\" + 0.007*\"good\" + 0.006*\"singer\" + 0.006*\"kaleb\"')\n",
      " \n",
      "Kelly_Clarkson Tish_Haynes_Keys\n",
      " \n",
      "(0, '0.021*\"song\" + 0.020*\"kyla\" + 0.012*\"jackie\" + 0.012*\"top\" + 0.012*\"go\" + 0.010*\"sing\" + 0.010*\"like\" + 0.008*\"christiana\" + 0.008*\"12\" + 0.008*\"good\" + 0.008*\"get\" + 0.008*\"jade\"')\n",
      "(1, '0.013*\"season\" + 0.012*\"good\" + 0.012*\"like\" + 0.011*\"voice\" + 0.011*\"country\" + 0.011*\"get\" + 0.010*\"make\" + 0.009*\"tish\" + 0.009*\"singer\" + 0.009*\"win\" + 0.009*\"go\" + 0.009*\"think\"')\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Adam_Levine=['Drew_Cole','Jackie_Verna','Mia_Boostrom','Reid_Umstattd']\n",
    "Alicia_Keys=['Johnny_Bliss','Christiana_Danielle','Kelsea_Johnson','Terrence_Cunningham']\n",
    "Blake_Shelton=['Austin_Giorgio','Gary_Edwards','Spensha_Baker','Wilkes']\n",
    "Kelly_Clarkson=['Alexa_Cappelli','D.R._King','Dylan_Hartigan','Tish_Haynes_Keys']\n",
    "experts={'Alicia_Keys':Alicia_Keys,'Adam_Levine':Adam_Levine,'Blake_Shelton':Blake_Shelton,'Kelly_Clarkson':Kelly_Clarkson}\n",
    "for key,value in experts.items():\n",
    "   \n",
    "        \n",
    "    for i in range(len(value)):\n",
    "        data=pd.read_csv(r'C:\\Users\\zgh\\Downloads\\text final\\{}\\{}.csv'.format(key,value[i]))\n",
    "        stop = set(stopwords.words('english'))\n",
    "        exclude = set(string.punctuation) \n",
    "        lemma = WordNetLemmatizer()\n",
    "        frames = [data['commentText'][pd.notna(data['commentText'])], \\\n",
    "                  data['replies.commentText'][pd.notna(data['replies.commentText'])]]\n",
    "        datanona=pd.concat(frames)\n",
    "    \n",
    "        def clean(doc):\n",
    "            stop_free = \" \".join([i for i in str(doc).lower().split() if i not in stop])\n",
    "            punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "            other_punc_free=''.join(ch for ch in punc_free if ch!='’')\n",
    "            normalized = \" \".join(lemma.lemmatize(word) for word in other_punc_free.split())\n",
    "            replacelove=normalized.replace('love','like')\n",
    "            pos_tagging_without_stopwords=nltk.pos_tag(replacelove.split())\n",
    "            def get_wordnet_pos(treebank_tag):\n",
    "                if treebank_tag.startswith('J'):\n",
    "                    return wordnet.ADJ\n",
    "                elif treebank_tag.startswith('V'):\n",
    "                    return wordnet.VERB\n",
    "                elif treebank_tag.startswith('N'):\n",
    "                    return wordnet.NOUN\n",
    "                elif treebank_tag.startswith('R'):\n",
    "                    return wordnet.ADV\n",
    "                else:\n",
    "                    return None\n",
    "            l=[]\n",
    "            for word, tag in pos_tagging_without_stopwords:\n",
    "                wntag = get_wordnet_pos(tag)\n",
    "                if wntag is None:\n",
    "                    lemma1 = lemma.lemmatize(word)\n",
    "                    l.append(lemma1)\n",
    "                else:\n",
    "                    lemma1 = lemma.lemmatize(word, pos=wntag) \n",
    "                    l.append(lemma1)\n",
    "            return ' '.join(l)\n",
    "        datacom=datanona.map(clean)\n",
    "        datacomtoken=datacom.map(word_tokenize)\n",
    "        id2word = corpora.Dictionary(datacomtoken)\n",
    "        corpus=[id2word.doc2bow(text) for text in datacomtoken]\n",
    "\n",
    "        NUM_TOPICS = 2\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=id2word, passes=15)\n",
    "        topics = ldamodel.print_topics(num_words=12)\n",
    "        print (key,value[i])\n",
    "        print(' ')\n",
    "        #vis_data = gensimvis.prepare(ldamodel, corpus, id2word)\n",
    "        #pyLDAvis.display(vis_data)\n",
    "        for topic in topics:\n",
    "            print(topic)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all the comments(5 topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "(0, '0.027*\"top\" + 0.018*\"12\" + 0.017*\"performance\" + 0.014*\"go\" + 0.013*\"good\" + 0.013*\"kelsea\" + 0.012*\"really\" + 0.012*\"im\" + 0.011*\"one\" + 0.011*\"christiana\" + 0.010*\"jackie\" + 0.010*\"make\"')\n",
      "(1, '0.034*\"like\" + 0.021*\"voice\" + 0.017*\"song\" + 0.014*\"get\" + 0.013*\"make\" + 0.013*\"country\" + 0.012*\"vote\" + 0.012*\"it\" + 0.011*\"go\" + 0.010*\"show\" + 0.009*\"sing\" + 0.009*\"well\"')\n",
      "(2, '0.032*\"dr\" + 0.026*\"team\" + 0.026*\"jackie\" + 0.022*\"kelly\" + 0.020*\"kaleb\" + 0.015*\"blake\" + 0.015*\"adam\" + 0.011*\"king\" + 0.011*\"spensha\" + 0.010*\"pryor\" + 0.009*\"alicia\" + 0.009*\"well\"')\n",
      "(3, '0.026*\"like\" + 0.021*\"agree\" + 0.017*\"na\" + 0.015*\"im\" + 0.015*\"gon\" + 0.013*\"you\" + 0.009*\"comment\" + 0.009*\"move\" + 0.009*\"tish\" + 0.007*\"miss\" + 0.006*\"leave\" + 0.006*\"what\"')\n",
      "(4, '0.040*\"song\" + 0.020*\"good\" + 0.016*\"choice\" + 0.015*\"vocal\" + 0.014*\"kyla\" + 0.013*\"great\" + 0.012*\"note\" + 0.011*\"singer\" + 0.009*\"people\" + 0.008*\"range\" + 0.008*\"bad\" + 0.008*\"tom\"')\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Adam_Levine=['Drew_Cole','Jackie_Verna','Mia_Boostrom','Reid_Umstattd']\n",
    "Alicia_Keys=['Johnny_Bliss','Christiana_Danielle','Kelsea_Johnson','Terrence_Cunningham']\n",
    "Blake_Shelton=['Austin_Giorgio','Gary_Edwards','Spensha_Baker','Wilkes']\n",
    "Kelly_Clarkson=['Alexa_Cappelli','D.R._King','Dylan_Hartigan','Tish_Haynes_Keys']\n",
    "experts={'Alicia_Keys':Alicia_Keys,'Adam_Levine':Adam_Levine,'Blake_Shelton':Blake_Shelton,'Kelly_Clarkson':Kelly_Clarkson}\n",
    "allthecsv=[]\n",
    "for key,value in experts.items():\n",
    "    for i in range(len(value)):\n",
    "        value[i]=pd.read_csv(r'C:\\Users\\zgh\\Downloads\\text final\\{}\\{}.csv'.format(key,value[i]))\n",
    "        allthecsv.append(value[i])\n",
    "data=pd.concat(allthecsv)\n",
    "frames = [data['commentText'][pd.notna(data['commentText'])],data['replies.commentText'][pd.notna(data['replies.commentText'])]]\n",
    "datanona=pd.concat(frames)\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in str(doc).lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    other_punc_free=''.join(ch for ch in punc_free if ch!='’')\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in other_punc_free.split())\n",
    "    replacelove=normalized.replace('love','like')\n",
    "    pos_tagging_without_stopwords=nltk.pos_tag(replacelove.split())\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "    l=[]\n",
    "    for word, tag in pos_tagging_without_stopwords:\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if wntag is None:\n",
    "            lemma1 = lemma.lemmatize(word)\n",
    "            l.append(lemma1)\n",
    "        else:\n",
    "            lemma1 = lemma.lemmatize(word, pos=wntag) \n",
    "            l.append(lemma1)\n",
    "    return ' '.join(l)\n",
    "datacom=datanona.map(clean)\n",
    "datacomtoken=datacom.map(word_tokenize)\n",
    "id2word = corpora.Dictionary(datacomtoken)\n",
    "corpus=[id2word.doc2bow(text) for text in datacomtoken]\n",
    "\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=id2word, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=12)\n",
    "print(' ')\n",
    "#vis_data = gensimvis.prepare(ldamodel, corpus, id2word)\n",
    "#pyLDAvis.display(vis_data)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
