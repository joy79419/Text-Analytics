{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "\n",
    "%pylab inline\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#comments are coming in as utf-8 so I am using this code to change it back to ascii\n",
    "def unicodetoascii(text):\n",
    "\n",
    "    TEXT = (text.\n",
    "    \t\treplace('\\xe2\\x80\\x99', \"'\").\n",
    "            replace('\\xc3\\xa9', 'e').\n",
    "            replace('\\xe2\\x80\\x90', '-').\n",
    "            replace('\\xe2\\x80\\x91', '-').\n",
    "            replace('\\xe2\\x80\\x92', '-').\n",
    "            replace('\\xe2\\x80\\x93', '-').\n",
    "            replace('\\xe2\\x80\\x94', '-').\n",
    "            replace('\\xe2\\x80\\x94', '-').\n",
    "            replace('\\xe2\\x80\\x98', \"'\").\n",
    "            replace('\\xe2\\x80\\x9b', \"'\").\n",
    "            replace('\\xe2\\x80\\x9c', '\"').\n",
    "            replace('\\xe2\\x80\\x9c', '\"').\n",
    "            replace('\\xe2\\x80\\x9d', '\"').\n",
    "            replace('\\xe2\\x80\\x9e', '\"').\n",
    "            replace('\\xe2\\x80\\x9f', '\"').\n",
    "            replace('\\xe2\\x80\\xa6', '...').#\n",
    "            replace('\\xe2\\x80\\xb2', \"'\").\n",
    "            replace('\\xe2\\x80\\xb3', \"'\").\n",
    "            replace('\\xe2\\x80\\xb4', \"'\").\n",
    "            replace('\\xe2\\x80\\xb5', \"'\").\n",
    "            replace('\\xe2\\x80\\xb6', \"'\").\n",
    "            replace('\\xe2\\x80\\xb7', \"'\").\n",
    "            replace('\\xe2\\x81\\xba', \"+\").\n",
    "            replace('\\xe2\\x81\\xbb', \"-\").\n",
    "            replace('\\xe2\\x81\\xbc', \"=\").\n",
    "            replace('\\xe2\\x81\\xbd', \"(\").\n",
    "            replace('\\xe2\\x81\\xbe', \")\")\n",
    "\n",
    "                 )\n",
    "    return TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final.csv', sep=',',names=['id', 'date','user','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.index[:1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>September 7</td>\n",
       "      <td>dino001</td>\n",
       "      <td>If they keep it around in next four-five years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>September 7</td>\n",
       "      <td>circlew</td>\n",
       "      <td>The lease rate is the factor that stops me col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>September 8</td>\n",
       "      <td>qbrozen</td>\n",
       "      <td>Yes, the completely noncomparable M2 would bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>September 9</td>\n",
       "      <td>FlightNurse2</td>\n",
       "      <td>Why not a Genesis G70 with a manual?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>September 9</td>\n",
       "      <td>roadburner</td>\n",
       "      <td>Again, the local dealer are hopeless at best(W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         date          user  \\\n",
       "1  0.0  September 7       dino001   \n",
       "2  1.0  September 7       circlew   \n",
       "3  2.0  September 8       qbrozen   \n",
       "4  3.0  September 9  FlightNurse2   \n",
       "5  4.0  September 9    roadburner   \n",
       "\n",
       "                                                text  \n",
       "1  If they keep it around in next four-five years...  \n",
       "2  The lease rate is the factor that stops me col...  \n",
       "3  Yes, the completely noncomparable M2 would bea...  \n",
       "4               Why not a Genesis G70 with a manual?  \n",
       "5  Again, the local dealer are hopeless at best(W...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text field is the comments field\n",
    "#unicodetoascii changes the form from unicoding to regular english\n",
    "#making all the comments lower case\n",
    "#dt = data.iloc[:50]\n",
    "text = data['text']\n",
    "text = text.map(lambda a: unicodetoascii(str(a)))\n",
    "text = text.map(lambda a: a.lower())\n",
    "\n",
    "#text= text.map(lambda a: str(a).decode('ascii', errors='ignore'))\n",
    "#text_18 = text.loc[18]\n",
    "\n",
    "#text_18 = text_18.decode(\"ascii\", errors=\"ignore\")\n",
    "#text_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = pd.read_csv('models.csv', sep=',',names=['brand','model'],encoding='windows-1252')\n",
    "models_revised = pd.read_csv('models_revised.csv', sep=',',names=['brand','model'],encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this text is also in unicode so just replacing one of the symbols with a space \n",
    "#(we can also call the unicodetoascii function here for more robust cleaning)\n",
    "#making the model names lowercase\n",
    "models.model = models['model'].map(lambda x: x.replace('\\xa0', ''))\n",
    "models.model = models['model'].map(lambda x: x.lower())\n",
    "models_revised.model = models_revised['model'].map(lambda x: x.replace('\\xa0', ''))\n",
    "models_revised.model = models_revised['model'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary {model: brand}\n",
    "#this will be used when locating when the model is written, and replacing it to the brand name\n",
    "brand_dict = {}\n",
    "for i in range(len(models_revised)):\n",
    "    brand_dict[models_revised['model'][i]] = models_revised['brand'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace all models with brand names\n",
    "\n",
    "\n",
    "#for key in brand_dict.iterkeys():\n",
    " #   dt['text'] = dt['text'].map(lambda x: x.replace(key, brand_dict[key]))\n",
    "    \n",
    "#dt['text']\n",
    "#for key in brand_dict.iterkeys():\n",
    "#    text_18 = text_18.replace(key, brand_dict[key])\n",
    "#text_18\n",
    "\n",
    "def replace(match):\n",
    "    return brand_dict[match.group(0)]\n",
    "\n",
    "text = text.map(lambda x: re.sub('|'.join(r'%s' % re.escape(s) for s in brand_dict), \n",
    "        replace, x) )\n",
    "\n",
    "#text_18 =  re.sub('|'.join(r'\\b%s' % re.escape(s) for s in brand_dict), \n",
    "#        replace, text_18) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all of the unique/different brand names\n",
    "brand = list(set(models_revised.brand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#findall: takes each comment separately, finds every time any brand is mentioned, and adds it to the master list\n",
    "#set(ls): this makes sure that even if the brand is mentioned more than once, it is only recorded once\n",
    "master_list = []\n",
    "\n",
    "def findall(w):\n",
    "    ls = []\n",
    "    ls = [e for e in brand for i in w.split() if e in i] #this line finds where the brand is mentioned in the comment (could be\n",
    "    # of any format: ex. \"honda.\"| \"honda's\" | \"honda-and\" | etc., and records it as just \"honda\")\n",
    "    ls = list(set(ls))\n",
    "    master_list.append(ls) #this stores all the mentions of every comment we have\n",
    "text.map(findall)\n",
    "\n",
    "count_list = sum(master_list)\n",
    "\n",
    "brand_mention_doc = master_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmw           532\n",
       "toyota        504\n",
       "audi          460\n",
       "honda         246\n",
       "acura         217\n",
       "chrysler      150\n",
       "volkswagen    121\n",
       "infiniti      106\n",
       "hyundai       103\n",
       "cadillac       98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_series = pd.Series(count_list).value_counts()\n",
    "count_series[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bmw', 532),\n",
       " ('toyota', 504),\n",
       " ('audi', 460),\n",
       " ('honda', 246),\n",
       " ('acura', 217),\n",
       " ('chrysler', 150),\n",
       " ('volkswagen', 121),\n",
       " ('infiniti', 106),\n",
       " ('hyundai', 103),\n",
       " ('cadillac', 98)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#counts the number of mentions each brand has and displays the top 10\n",
    "\n",
    "counts = Counter(count_list)\n",
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list = []\n",
    "#list = [i for e in brand for i in text_18.split() if e in i]\n",
    "#for b in brand:\n",
    "#    for c in list:\n",
    "#        if re.search(b , c):\n",
    "#            list = [word.replace(c,b) for word in list]\n",
    "#set(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ratio(a, b):\n",
    "#    a = float(a)\n",
    "#    b = float(b)\n",
    "#    if b == 0:\n",
    "#        return a\n",
    "#    return ratio(b, a % b)\n",
    "\n",
    "#def get_ratio(a, b):\n",
    "#    r = ratio(a, b)\n",
    "#    return \"%s\" % float((a/r) / (b/r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list = list(filter(None,master_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occur(car1, car2):\n",
    "    freq = 0\n",
    "    for i in range(len(master_list)):\n",
    "        if (car1 in master_list[i]) & (car2 in master_list[i]):\n",
    "            freq += 1\n",
    "    return freq\n",
    "\n",
    "def lift(car1, car2):\n",
    "    return (float(len(text)) * float(co_occur(car1, car2))) / (float(count_series.loc[car1]) * float(count_series.loc[car2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bmw', 'toyota') 1.5777949337629789\n",
      "('bmw', 'audi') 1.999476953252697\n",
      "('bmw', 'honda') 1.713643865761966\n",
      "('bmw', 'acura') 1.2803870274765254\n",
      "('bmw', 'chrysler') 0.5748496240601504\n",
      "('bmw', 'volkswagen') 0.8709842788790157\n",
      "('bmw', 'infiniti') 1.4461625762519505\n",
      "('bmw', 'hyundai') 1.7673370319001387\n",
      "('bmw', 'cadillac') 1.8575072886297377\n",
      "('toyota', 'audi') 1.8027691511387163\n",
      "('toyota', 'honda') 2.795489740611692\n",
      "('toyota', 'acura') 1.2583113890717577\n",
      "('toyota', 'chrysler') 2.2248809523809525\n",
      "('toyota', 'volkswagen') 2.0059031877213696\n",
      "('toyota', 'infiniti') 1.8127246181491465\n",
      "('toyota', 'hyundai') 2.061893203883495\n",
      "('toyota', 'cadillac') 2.063896987366375\n",
      "('audi', 'honda') 1.6215270413573701\n",
      "('audi', 'acura') 2.1446002805049087\n",
      "('audi', 'chrysler') 1.699\n",
      "('audi', 'volkswagen') 4.029249011857708\n",
      "('audi', 'infiniti') 4.285828547990156\n",
      "('audi', 'hyundai') 1.7212325875897003\n",
      "('audi', 'cadillac') 2.035181898846495\n",
      "('honda', 'acura') 5.346970889063729\n",
      "('honda', 'chrysler') 5.939593495934959\n",
      "('honda', 'volkswagen') 2.7397702076194315\n",
      "('honda', 'infiniti') 1.7592038656235618\n",
      "('honda', 'hyundai') 1.8104428131659958\n",
      "('honda', 'cadillac') 1.4799651567944252\n",
      "('acura', 'chrysler') 7.672903225806452\n",
      "('acura', 'volkswagen') 1.164717979967247\n",
      "('acura', 'infiniti') 5.096556821145987\n",
      "('acura', 'hyundai') 1.368260927922688\n",
      "('acura', 'cadillac') 1.9174268785855355\n",
      "('chrysler', 'volkswagen') 0.5616528925619835\n",
      "('chrysler', 'infiniti') 0.9616981132075472\n",
      "('chrysler', 'hyundai') 0.9897087378640776\n",
      "('chrysler', 'cadillac') 1.040204081632653\n",
      "('volkswagen', 'infiniti') 0.0\n",
      "('volkswagen', 'hyundai') 2.86279386985477\n",
      "('volkswagen', 'cadillac') 1.2895091921065946\n",
      "('infiniti', 'hyundai') 0.9336874885510167\n",
      "('infiniti', 'cadillac') 2.453311513284559\n",
      "('hyundai', 'cadillac') 1.5148603130572618\n"
     ]
    }
   ],
   "source": [
    "top_10_brand = list(count_series[:10].index.values)\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "for combo in combinations(list(count_series[:10].index.values), 2):\n",
    "    print(combo,lift(combo[0],combo[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "for car1 in top_10_brand:\n",
    "    group_dist=[]\n",
    "    for car2 in top_10_brand:\n",
    "        if (lift(car1, car2) != 0) & (car1 != car2):\n",
    "            group_dist.append(1/lift(car1, car2))\n",
    "        elif (lift(car1, car2) != 0) & (car1 == car2):\n",
    "            group_dist.append(0.0)\n",
    "        else:\n",
    "            group_dist.append(4.0)\n",
    "    dist_list.append(group_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunhsiangchang/anaconda2/envs/Python3/lib/python3.6/site-packages/sklearn/manifold/mds.py:411: UserWarning: The MDS API has changed. ``fit`` now constructs an dissimilarity matrix from data. To use a custom dissimilarity matrix, set ``dissimilarity='precomputed'``.\n",
      "  warnings.warn(\"The MDS API has changed. ``fit`` now constructs an\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2)\n",
    "pos = mds.fit(dist_list).embedding_\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pos[:, 0], pos[:, 1], color='turquoise')\n",
    "for i, txt in enumerate(top_10_brand):\n",
    "    ax.annotate(txt, (pos[:, 0][i], pos[:, 1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the words that are mentioned the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess(x):\n",
    "    lowercase= x.lower()\n",
    "    for p in punctuation:\n",
    "        lowercase = lowercase.replace(p,'')\n",
    "    return lowercase\n",
    "\n",
    "token = text.map(preprocess).map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [if, they, keep, it, around, in, next, fourfiv...\n",
       "2    [the, lease, rate, is, the, factor, that, stop...\n",
       "3    [yes, the, completely, noncomparable, m2, woul...\n",
       "4         [why, not, a, hyundai, g70, with, a, manual]\n",
       "5    [again, the, local, dealer, are, hopeless, at,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_sentence = [] \n",
    "\n",
    "def remove_stopwords(x):\n",
    "    for w in x: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "token.map(remove_stopwords)\n",
    "pos_tagging = nltk.pos_tag(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('keep', 'VB'),\n",
       " ('around', 'IN'),\n",
       " ('next', 'JJ'),\n",
       " ('fourfive', 'JJ'),\n",
       " ('years', 'NNS')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "l = []\n",
    "for word, tag in pos_tagging:\n",
    "    wntag = get_wordnet_pos(tag)\n",
    "    if wntag is None:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        l.append(lemma)\n",
    "    else:\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wntag) \n",
    "        l.append(lemma)\n",
    "\n",
    "words_value_counts = pd.Series(l).value_counts()\n",
    "words_value_counts.to_csv('Word_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lemmatize every message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pos = token.map(nltk.pos_tag) ## Tokennize all text in order to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_msg(x):\n",
    "    msg_l = []\n",
    "    for word, tag in x:\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if wntag is None:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            msg_l.append(lemma)\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wntag) \n",
    "            msg_l.append(lemma)\n",
    "    return msg_l\n",
    "\n",
    "token_lemm = pd.Series(token_pos).map(lemm_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'they',\n",
       " 'keep',\n",
       " 'it',\n",
       " 'around',\n",
       " 'in',\n",
       " 'next',\n",
       " 'fourfive',\n",
       " 'year',\n",
       " 'i',\n",
       " 'think',\n",
       " 'i',\n",
       " 'will',\n",
       " 'make',\n",
       " 'myself',\n",
       " 'to',\n",
       " 'put',\n",
       " 'on',\n",
       " 'a',\n",
       " 'hazmat',\n",
       " 'suit',\n",
       " 'and',\n",
       " 'visit',\n",
       " 'our',\n",
       " 'friendly',\n",
       " 'kia',\n",
       " 'dealer',\n",
       " 'oh',\n",
       " 'boy',\n",
       " 'be',\n",
       " 'they',\n",
       " 'horrible',\n",
       " 'here',\n",
       " 'or',\n",
       " 'what',\n",
       " 'to',\n",
       " 'check',\n",
       " 'it',\n",
       " 'out',\n",
       " 'it',\n",
       " 'get',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'good',\n",
       " 'stuff',\n",
       " 'but',\n",
       " 'seem',\n",
       " 'like',\n",
       " 'they',\n",
       " 'be',\n",
       " 'still',\n",
       " 'behind',\n",
       " 'on',\n",
       " 'a',\n",
       " 'few',\n",
       " 'thing',\n",
       " 'such',\n",
       " 'a',\n",
       " 'relationship',\n",
       " 'between',\n",
       " 'power',\n",
       " 'and',\n",
       " 'gas',\n",
       " 'mileage',\n",
       " 'eg',\n",
       " 'bmw',\n",
       " '340440',\n",
       " 'have',\n",
       " 'similar',\n",
       " 'performance',\n",
       " 'but',\n",
       " 'much',\n",
       " 'good',\n",
       " 'gas',\n",
       " 'mileage',\n",
       " 'a',\n",
       " 'a',\n",
       " 'daily',\n",
       " 'driver',\n",
       " 'but',\n",
       " 'with',\n",
       " 'appropriate',\n",
       " 'price',\n",
       " 'difference',\n",
       " 'those',\n",
       " 'objection',\n",
       " 'and',\n",
       " 'shortcoming',\n",
       " 'be',\n",
       " 'not',\n",
       " 'insurmountable',\n",
       " 'big',\n",
       " 'thing',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'first',\n",
       " 'contact',\n",
       " 'with',\n",
       " 'a',\n",
       " 'sale',\n",
       " 'person',\n",
       " 'hope',\n",
       " 'it',\n",
       " 'wont',\n",
       " 'start',\n",
       " 'from',\n",
       " 'be',\n",
       " 'you',\n",
       " 'buy',\n",
       " 'it',\n",
       " 'today',\n",
       " 'what',\n",
       " 'can',\n",
       " 'i',\n",
       " 'do',\n",
       " 'to',\n",
       " 'make',\n",
       " 'you',\n",
       " 'take',\n",
       " 'it',\n",
       " 'home',\n",
       " 'or',\n",
       " 'let',\n",
       " 'me',\n",
       " 'wash',\n",
       " 'your',\n",
       " 'bmw',\n",
       " 'oh',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'find',\n",
       " 'the',\n",
       " 'key',\n",
       " 'how',\n",
       " 'about',\n",
       " 'i',\n",
       " 'show',\n",
       " 'you',\n",
       " 'the',\n",
       " 'deal',\n",
       " 'square',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lemm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_sring(x):\n",
    "    return ' '.join(x)\n",
    "text_lemm = token_lemm.map(list_to_sring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = pd.read_csv('att.csv', sep = ',',names=['attribute','word'], encoding='windows-1252')\n",
    "att.word = att['word'].map(lambda x: x.replace('\\xa0', ''))\n",
    "att.word = att['word'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       if they keep it around in next fourfive year i...\n",
       "2       the lease rate be the factor that stop me cold...\n",
       "3       yes the completely noncomparable m2 would beat...\n",
       "4                     why not a hyundai g70 with a manual\n",
       "5       again the local dealer be hopeless at bestwhat...\n",
       "6       be you talk about hyundai dealer or hyundia de...\n",
       "7       thanks but i be more than aware of the dtoyota...\n",
       "8       yeah i go once to an autonation lexus store it...\n",
       "9       i be the poster formerly know a benjaminh and ...\n",
       "10      still on the ltoyota just have not be look act...\n",
       "11                                   i send you a message\n",
       "12      a new and mostly positive review by kelly blue...\n",
       "13      if i do manage to upgrade to a tchrysler it wo...\n",
       "14      thanks ill give it a try at some point to merg...\n",
       "15      im not sure if id have the patience and discip...\n",
       "16      they usually go up a the year go along chrtoyo...\n",
       "17      yeah i be and be a bit concerned with get two ...\n",
       "18      the ktoyota reviewer make some good point abou...\n",
       "19      i like the 2 screen set up for just the reason...\n",
       "20      my local cadillac dealer have their last at av...\n",
       "21          i would take it without even look at the link\n",
       "22      that dealer have the same gm a my bmw dealer t...\n",
       "23      the fine lrint for all say plus dealer addons ...\n",
       "24      the ct look like a smokin â€™ n deal if your nam...\n",
       "25      so the car be 199month and the mop and glow st...\n",
       "26             if i be 25 year old i might an xt5 as well\n",
       "27      it a hard knock life when 060 in 65 sec in an ...\n",
       "28      one of the feature i like on my tchryslers ste...\n",
       "29      whats the storage capahonda in gb if uncompres...\n",
       "30      good question try to look it up at the acura w...\n",
       "                              ...                        \n",
       "5068    i do find it annoy the xxx number be model fro...\n",
       "5069    graphicguy have the dealer apply the performan...\n",
       "5070    i think the be be available on coupe only beca...\n",
       "5071    igraphicguy have the dealer apply the performa...\n",
       "5072    graphicguy have the dealer apply the performan...\n",
       "5073    it be retoyotad by a couple of vendor that the...\n",
       "5074    fnnope mine be the bmw with the performance pa...\n",
       "5075    i do find it annoy the xxx number be model fro...\n",
       "5076    you should have put a dinan sticker on your re...\n",
       "5077                            it be actually the 370 tq\n",
       "5078    when i buy my bmw the model designation have a...\n",
       "5079                  yes thats an often overlooked tweak\n",
       "5080    oh yeah sutoyotaed in black grille they soak u...\n",
       "5081    oh boy well be up to 400 hp and 40 mpg the rat...\n",
       "5082    i be look thru the inventory at a local bmw de...\n",
       "5083    im consider a preowned 2012 or 2013 when i go ...\n",
       "5084    i didnt observe this trend here yet majority 3...\n",
       "5085    oh boy well be up to 400 hp and 40 mpg the rat...\n",
       "5086    ive technically just order my custom equip and...\n",
       "5087    observation and opinion dont see many 335 seda...\n",
       "5088    our company 45k mile honda have a warped rotor...\n",
       "5089    it be imperial blue dark or estoril blue light...\n",
       "5090                                                  nan\n",
       "5091    i didnt opt for a rear backup camera on my nex...\n",
       "5092    get a go pro camera and mt to dash plenty of r...\n",
       "5093    im with you backup camera be quite helpful a b...\n",
       "5094    mark i in the last 3 month i have have 4 infin...\n",
       "5095    you know what else be huge the money i save by...\n",
       "5096                         ahhh i misspoke and miswrote\n",
       "5097    yeah those line be useful for spot i also like...\n",
       "Name: text, Length: 5097, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_dict = {}\n",
    "for i in range(len(att)):\n",
    "    att_dict[att['word'][i]] = att['attribute'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_att(x):\n",
    "    return att_dict[x.group(0)]\n",
    "\n",
    "text_att = text_lemm.map(lambda x: re.sub('|'.join(r'%s' % re.escape(s) for s in att_dict), \n",
    "        replace_att, x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_brand = list(count_series[:5].index.values)\n",
    "attribute_list = list(att['attribute'].unique())\n",
    "co_occur_list = top_5_brand + attribute_list\n",
    "master_list_att = []\n",
    "\n",
    "def findall_att(w):\n",
    "    ls = []\n",
    "    ls = [e for e in co_occur_list for i in w.split() if e in i]\n",
    "    ls = list(set(ls))\n",
    "    master_list_att.append(ls)\n",
    "text_att.map(findall_att)\n",
    "\n",
    "#master_list_att = list(filter(None,master_list_att))\n",
    "count_list_att = sum(master_list_att)\n",
    "count_series_att = pd.Series(count_list_att).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration       1022\n",
       "performance     759\n",
       "price           611\n",
       "design          598\n",
       "bmw             532\n",
       "toyota          504\n",
       "audi            460\n",
       "size            276\n",
       "honda           246\n",
       "acura           217\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_series_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occur_att(car, att):\n",
    "    freq = 0\n",
    "    for i in range(len(master_list_att)):\n",
    "        if (car in master_list_att[i]) & (att in master_list_att[i]):\n",
    "            freq += 1\n",
    "    return freq\n",
    "\n",
    "def lift_att(car, att):\n",
    "    return (float(len(text_att)) * float(co_occur_att(car, att))) / (float(count_series_att.loc[car]) * float(count_series_att.loc[att]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmw size 1.9092227852239294\n",
      "bmw performance 1.7040996760676395\n",
      "bmw design 1.8584881937284683\n",
      "bmw price 1.991432140088355\n",
      "bmw duration 1.7905459588305401\n",
      "toyota size 2.2717822636300897\n",
      "toyota performance 2.025283894849112\n",
      "toyota design 2.1477643733078517\n",
      "toyota price 2.019308705478918\n",
      "toyota duration 1.969183906439288\n",
      "audi size 2.087618147448015\n",
      "audi performance 1.8832359511943633\n",
      "audi design 2.316144394358005\n",
      "audi price 1.614007685191774\n",
      "audi duration 1.5070258657364077\n",
      "honda size 2.7025450689289503\n",
      "honda performance 2.1292779330955365\n",
      "honda design 2.148176849661473\n",
      "honda price 1.8990060277034848\n",
      "honda duration 2.0476230251539307\n",
      "acura size 2.297786014826688\n",
      "acura performance 1.7639569406750333\n",
      "acura design 2.003198064207882\n",
      "acura price 1.8452487800463093\n",
      "acura duration 1.9535427958191673\n"
     ]
    }
   ],
   "source": [
    "for brand in top_5_brand:\n",
    "    for attribute in attribute_list:\n",
    "        print(brand, attribute, lift_att(brand, attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMW:\n",
    "Surprisingly, BMW has low lift on most of the 5 attributes except price. It can be caused by the users on online-forum are younger and couldn't afford a BMW.\n",
    "### Toyota:\n",
    "By having a comparatively high lift on all attributes, it seems that Toyota serves as a benchmark in discussions on attributes. People like to compare the dicussion between buying a car under dicussion with buying a Toyota. Which suggest the prevalence of Toyota because of the relatively good quality given the price.\n",
    "### Audi:\n",
    "Having the highest lift on design among the five brands. Audi has an advantage on attracting people's eyeballs by how the car looks.\n",
    "### Honda: \n",
    "It seems that people are more concerned on the size of Honda's car and how long could the car be drive with little maintenance. Therefore, size and duration are the attributes Honda needs to emphasize on its commercials.\n",
    "### Acura:\n",
    "People talk more about Acura's size and design, which seems to be the strength of the brand. However, Acura should notice Edmunds user are talking less about the Acura's performance, which could be its weakness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In task E, we first define a list of \"aspiring words\". Next, we searched if any of the \"aspiring words\" appear in the lemmatized, stop word removed text. Then, we find three words in both the front and the end of the \"aspiring word\" found, and check if any brand names in these six words. If brand name found, we found an incidence of expressing asipiration to a brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import snowball\n",
    "import string\n",
    "stop_w = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    return([w for w in tokens if not w in stop_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words from the token of lemmantized comments\n",
    "token_lem_s_removed = token_lemm.map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspiring_words = [\"want\", \"dream\", \"hope\", \"wish\", \"aspire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_aspiring = []\n",
    "for index, brand_mentioned in enumerate(brand_mention_doc):\n",
    "    \n",
    "    #for each text, create an dictionary of mentioned {brand : list of asipiring words} \n",
    "    brand_attribute_dict = {}\n",
    "    if brand_mentioned:\n",
    "        for word_index, word in enumerate(token_lem_s_removed.iloc[index]):\n",
    "            \n",
    "            if word in aspiring_words:\n",
    "                #This creates a list of length 7 having the attribute word in the midle\n",
    "                vicinity_word_list = token_lem_s_removed.iloc[index][word_index-3 : word_index+4] \n",
    "                for brand in brand_mentioned:\n",
    "                    \n",
    "                    if brand in vicinity_word_list:\n",
    "                        #Find the index of the brand in our text token list\n",
    "                        brand_index = vicinity_word_list.index(brand)\n",
    "                        #Check if there is period between found aspiration word and brand\n",
    "                        if (brand_index > 3 ) and (\".\" in vicinity_word_list[3 : brand_index]):\n",
    "                            continue\n",
    "                        elif (brand_index < 3) and (\".\" in vicinity_word_list[brand_index : 3]):\n",
    "                            continue\n",
    "                        else:\n",
    "                            if brand not in brand_attribute_dict:\n",
    "                                brand_attribute_dict[brand] = [word]\n",
    "                            else:\n",
    "                                brand_attribute_dict[brand].append(word)\n",
    "                                                                                      \n",
    "    master_list_aspiring.append(brand_attribute_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'honda': ['wish']},\n",
       " {'cadillac': ['want']},\n",
       " {'kia': ['want']},\n",
       " {'kia': ['want'], 'hyundai': ['want']},\n",
       " {'kia': ['hope']}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_list_aspiring_f = list(filter(None,master_list_aspiring))\n",
    "master_list_aspiring_f[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the found pairs of brand and aspiration words to Pandas Series \n",
    "brands_aspire_count_dict = {}\n",
    "for i in master_list_aspiring_f:\n",
    "    for j in i.keys():\n",
    "        if j not in brands_aspire_count_dict:\n",
    "            brands_aspire_count_dict[j] = 1\n",
    "        else:\n",
    "            brands_aspire_count_dict[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmw         11\n",
       "audi         7\n",
       "toyota       6\n",
       "infiniti     5\n",
       "honda        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(brands_aspire_count_dict).sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, the most aspirational brand on Edmunds is BMW. However, we can find from the lift analysis in Task C, people aren't talking about BMW's car attributes a lot. Which implicates BMW has formed a good image among Edmunds users, but has created little surprise and discussion on its car attributes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
